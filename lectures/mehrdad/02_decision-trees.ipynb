{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](../img/330-banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Lecture 2: Terminology, Baselines, Decision Trees\n",
    "\n",
    "UBC 2023-24\n",
    "\n",
    "Instructors: Mathias Lécuyer and Mehrdad Oveisi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements \n",
    "\n",
    "- Things due next Monday \n",
    "    - Homework 0 (Syllabus quiz, on PrairieLearn): Sept 15, 11:59pm\n",
    "    - Homework 1 (hw1 on github, submitted to PrairieLearn): Sept 15, 11:59pm\n",
    "- You can find the tentative due dates for all deliverables [here](https://github.com/UBC-CS/cpsc330-2023W2/tree/main#deliverable-due-dates-tentative).\n",
    "- Please monitor Piazza (especially pinned posts and instructor posts) for announcements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, LOs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:31.160807Z",
     "iopub.status.busy": "2024-01-11T23:11:31.160372Z",
     "iopub.status.idle": "2024-01-11T23:11:32.967162Z",
     "shell.execute_reply": "2024-01-11T23:11:32.965811Z",
     "shell.execute_reply.started": "2024-01-11T23:11:31.160764Z"
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "ExecuteTime": {
     "end_time": "2024-01-12T00:34:19.520342100Z",
     "start_time": "2024-01-12T00:34:12.650639400Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      9\u001B[0m sys\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../code/.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgraphviz\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m#import mglearn\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../code/.\")\n",
    "import graphviz\n",
    "import IPython\n",
    "#import mglearn\n",
    "from IPython.display import HTML, display\n",
    "from plotting_functions import *\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
    "from utils import *\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning outcomes \n",
    "From this lecture, you will be able to \n",
    "\n",
    "- identify whether a given problem could be solved using supervised machine learning or not; \n",
    "- differentiate between supervised and unsupervised machine learning;\n",
    "- explain machine learning terminology such as features, targets, predictions, training, and error;\n",
    "- differentiate between classification and regression problems;\n",
    "- use `DummyClassifier` and `DummyRegressor` as baselines for machine learning problems;\n",
    "- explain the `fit` and `predict` paradigm and use `score` method of ML models; \n",
    "- broadly describe how decision tree prediction works;\n",
    "- use `DecisionTreeClassifier` and `DecisionTreeRegressor` to build decision trees using `scikit-learn`; \n",
    "- visualize decision trees; \n",
    "- explain the difference between parameters and hyperparameters; \n",
    "- explain the concept of decision boundaries;\n",
    "- explain the relation between model complexity and decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Terminology [[video](https://youtu.be/YNT8n4cXu4A)]\n",
    "\n",
    "You will see a lot of variable terminology in machine learning and statistics. Let's familiarize ourselves with some of the basic terminology used in ML. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Check out [the accompanying video](https://youtu.be/YNT8n4cXu4A) on this material. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Big picture and datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we'll talk about our first machine learning model: **Decision trees**. We will also familiarize ourselves with some common terminology in supervised machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Toy datasets \n",
    "Later in the course we will use larger datasets from Kaggle, for instance. But for our first couple of lectures, we will be working with the following three **toy datasets**:\n",
    "\n",
    "- [Quiz2 grade prediction classification dataset](data/quiz2-grade-toy-classification.csv)\n",
    "- [Quiz2 grade prediction regression dataset](data/quiz2-grade-toy-regression.csv)\n",
    "- [Canada USA cities dataset](data/canada_usa_cities.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "___\n",
    "If it's not necessary for you to understand the code, I will put it in one of the files under the `code` directory to avoid clutter in this notebook. For example, most of the plotting code is going to be in `code/plotting_functions.py`. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I'll be using the following grade prediction toy dataset to demonstrate the terminology. Imagine that you are taking a course with four homework assignments and two quizzes. You and your friends are quite nervous about your quiz2 grades and you want to know how will you do based on your previous performance and some other attributes. So you decide to collect some data from your friends from last year and train a supervised machine learning model for quiz2 grade prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:32.970503Z",
     "iopub.status.busy": "2024-01-11T23:11:32.970051Z",
     "iopub.status.idle": "2024-01-11T23:11:32.987085Z",
     "shell.execute_reply": "2024-01-11T23:11:32.985431Z",
     "shell.execute_reply.started": "2024-01-11T23:11:32.970482Z"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-01-12T00:34:19.569347700Z",
     "start_time": "2024-01-12T00:34:19.528347Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv(\"data/quiz2-grade-toy-classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:32.989192Z",
     "iopub.status.busy": "2024-01-11T23:11:32.988484Z",
     "iopub.status.idle": "2024-01-11T23:11:33.004763Z",
     "shell.execute_reply": "2024-01-11T23:11:33.003039Z",
     "shell.execute_reply.started": "2024-01-11T23:11:32.989131Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.529347Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.007148Z",
     "iopub.status.busy": "2024-01-11T23:11:33.006695Z",
     "iopub.status.idle": "2024-01-11T23:11:33.035280Z",
     "shell.execute_reply": "2024-01-11T23:11:33.032980Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.007123Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.532342900Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Supervised machine learning\n",
    "\n",
    "<!-- ![](../img/sup-learning.png) -->\n",
    "<img src=\"../img/sup-learning.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tabular data\n",
    "In supervised machine learning, the input data is typically organized in a **tabular** format, where rows are **examples** and columns are **features**. One of the columns is typically the **target**. \n",
    "\n",
    "<!-- ![](../img/sup-ml-terminology.png) -->\n",
    "\n",
    "<img src=\"../img/sup-ml-terminology.png\" width=\"800\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Features** \n",
    ": Features are relevant characteristics of the problem, usually suggested by experts. Features are typically denoted by $X$ and the number of features is usually denoted by $d$.  \n",
    "\n",
    "**Target**\n",
    ": Target is the feature we want to predict (typically denoted by $y$). \n",
    "\n",
    "**Example** \n",
    ": A row of feature values. When people refer to an example, it may or may not include the target corresponding to the feature values, depending upon the context. The number of examples is usually denoted by $n$. \n",
    "\n",
    "**Training**\n",
    ": The process of learning the **mapping** between the features ($X$) and the target ($y$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example: Tabular data for grade prediction\n",
    "\n",
    "The tabular data usually contains both: the features (`X`) and the target (`y`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.039289Z",
     "iopub.status.busy": "2024-01-11T23:11:33.038733Z",
     "iopub.status.idle": "2024-01-11T23:11:33.058859Z",
     "shell.execute_reply": "2024-01-11T23:11:33.057251Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.039262Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.535344100Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv(\"data/quiz2-grade-toy-classification.csv\")\n",
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So the first step in training a supervised machine learning model is **separating `X` and `y`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.061043Z",
     "iopub.status.busy": "2024-01-11T23:11:33.060633Z",
     "iopub.status.idle": "2024-01-11T23:11:33.085101Z",
     "shell.execute_reply": "2024-01-11T23:11:33.083404Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.061015Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.539344400Z"
    }
   },
   "outputs": [],
   "source": [
    "X = classification_df.drop(columns=[\"quiz2\"])\n",
    "y = classification_df[\"quiz2\"]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.091118Z",
     "iopub.status.busy": "2024-01-11T23:11:33.089705Z",
     "iopub.status.idle": "2024-01-11T23:11:33.100649Z",
     "shell.execute_reply": "2024-01-11T23:11:33.097911Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.091061Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.543345300Z"
    }
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example: Tabular data for the housing price prediction\n",
    "\n",
    "Here is an example of tabular data for housing price prediction. You can download the data from [here](https://www.kaggle.com/harlfoxem/housesalesprediction). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.104228Z",
     "iopub.status.busy": "2024-01-11T23:11:33.103075Z",
     "iopub.status.idle": "2024-01-11T23:11:33.219025Z",
     "shell.execute_reply": "2024-01-11T23:11:33.216652Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.104176Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.547344500Z"
    }
   },
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv(\"data/kc_house_data.csv\")\n",
    "housing_df = housing_df.drop([\"id\", \"date\"], axis=1)\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.221004Z",
     "iopub.status.busy": "2024-01-11T23:11:33.220486Z",
     "iopub.status.idle": "2024-01-11T23:11:33.255259Z",
     "shell.execute_reply": "2024-01-11T23:11:33.252965Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.220961Z"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.551347Z"
    }
   },
   "outputs": [],
   "source": [
    "X = housing_df.drop(columns=[\"price\"])\n",
    "y = housing_df[\"price\"]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.258190Z",
     "iopub.status.busy": "2024-01-11T23:11:33.256993Z",
     "iopub.status.idle": "2024-01-11T23:11:33.265547Z",
     "shell.execute_reply": "2024-01-11T23:11:33.264277Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.258099Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.554345300Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.268022Z",
     "iopub.status.busy": "2024-01-11T23:11:33.267114Z",
     "iopub.status.idle": "2024-01-11T23:11:33.279126Z",
     "shell.execute_reply": "2024-01-11T23:11:33.277964Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.267985Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.558350600Z"
    }
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "___\n",
    "To a machine, column names (features) have no meaning. Only feature values and how they vary across examples mean something. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Alternative terminology for examples, features, targets, and training\n",
    "\n",
    "- **examples** = rows = samples = records = instances \n",
    "- **features** = inputs = predictors = explanatory variables = regressors = independent variables = covariates\n",
    "- **targets** = outputs = outcomes = response variable = dependent variable = labels (if categorical).\n",
    "- **training** = learning = fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Check out [the MDS terminology document](https://ubc-mds.github.io/resources_pages/terminology/). \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Supervised learning vs. Unsupervised learning\n",
    "\n",
    "In **supervised learning**, training data comprises a set of features ($X$) and their corresponding targets ($y$). We wish to find a **model function $f$** that relates $X$ to $y$. Then use that model function **to predict the targets** of new examples. \n",
    "\n",
    "\n",
    "<!-- ![](../img/sup-learning.png) -->\n",
    "\n",
    "<img src=\"../img/sup-learning.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In **unsupervised learning** training data consists of observations ($X$) **without any corresponding targets**. Unsupervised learning could be used to **group similar things together** in $X$ or to provide **concise summary** of the data. We'll learn more about this topic in later videos.\n",
    "\n",
    "<!-- ![](../img/unsup-learning.png) -->\n",
    "\n",
    "<img src=\"../img/unsup-learning.png\" alt=\"\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Supervised** machine learning is about **function approximation**, i.e., finding the mapping function from `X` to `y` \n",
    "- **Unsupervised** machine learning is about concisely **describing the data**.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification vs. Regression \n",
    "In *supervised machine learning*, there are two main kinds of learning problems based on what they are trying to predict.\n",
    "- **Classification problem**: predicting among two or more **discrete** classes\n",
    "    - Example1: Predict whether a patient has a liver disease or not\n",
    "    - Example2: Predict whether a student would get an A+ or not in quiz2.  \n",
    "- **Regression problem**: predicting a **continuous** value\n",
    "    - Example1: Predict housing prices \n",
    "    - Example2: Predict a student's score in quiz2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<!-- ![](../img/classification-vs-regression.png) -->\n",
    "<img src=\"../img/classification-vs-regression.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.280982Z",
     "iopub.status.busy": "2024-01-11T23:11:33.280486Z",
     "iopub.status.idle": "2024-01-11T23:11:33.300916Z",
     "shell.execute_reply": "2024-01-11T23:11:33.299317Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.280934Z"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.562345900Z"
    }
   },
   "outputs": [],
   "source": [
    "# quiz2 classification toy data\n",
    "classification_df = pd.read_csv(\"data/quiz2-grade-toy-classification.csv\")\n",
    "classification_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.304646Z",
     "iopub.status.busy": "2024-01-11T23:11:33.303578Z",
     "iopub.status.idle": "2024-01-11T23:11:33.329224Z",
     "shell.execute_reply": "2024-01-11T23:11:33.326846Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.304591Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.566345200Z"
    }
   },
   "outputs": [],
   "source": [
    "# quiz2 regression toy data\n",
    "regression_df = pd.read_csv(\"data/quiz2-grade-toy-regression.csv\")\n",
    "regression_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.331055Z",
     "iopub.status.busy": "2024-01-11T23:11:33.330668Z",
     "iopub.status.idle": "2024-01-11T23:11:33.340125Z",
     "shell.execute_reply": "2024-01-11T23:11:33.338305Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.331029Z"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-01-12T00:34:21.112804500Z",
     "start_time": "2024-01-12T00:34:19.570345Z"
    }
   },
   "outputs": [],
   "source": [
    "regression_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.342607Z",
     "iopub.status.busy": "2024-01-11T23:11:33.341983Z",
     "iopub.status.idle": "2024-01-11T23:11:33.367085Z",
     "shell.execute_reply": "2024-01-11T23:11:33.365925Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.342559Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.573346900Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.369703Z",
     "iopub.status.busy": "2024-01-11T23:11:33.368617Z",
     "iopub.status.idle": "2024-01-11T23:11:33.380639Z",
     "shell.execute_reply": "2024-01-11T23:11:33.378764Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.369561Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.578343Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ❓❓ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 2.1 Select all of the following statements which are examples of supervised machine learning \n",
    "\n",
    "1. How many examples and features are there in the housing price data above? You can use `df.shape` to get number of rows and columns in a dataframe. \n",
    "2. For each of the following examples what would be the relevant features and what would be the target?\n",
    "    1. Sentiment analysis\n",
    "    2. Fraud detection \n",
    "    3. Face recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "Exercise 2.1: One solution!\n",
    "1. Number of examples: 21613, number of features: 18 \n",
    "2. Open-ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.383850Z",
     "iopub.status.busy": "2024-01-11T23:11:33.383382Z",
     "iopub.status.idle": "2024-01-11T23:11:33.395397Z",
     "shell.execute_reply": "2024-01-11T23:11:33.393356Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.383812Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.582403100Z"
    }
   },
   "outputs": [],
   "source": [
    "housing_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iClicker Exercise 2.2 Supervised vs unsupervised\n",
    "\n",
    "**iClicker cloud join link: https://join.iclicker.com/FSLV**\n",
    "\n",
    "**Select all of the following statements which are examples of supervised machine learning**\n",
    "\n",
    "- (A) Finding groups of similar properties in a real estate data set.\n",
    "- (B) Predicting whether someone will have a heart attack or not on the basis of demographic, diet, and clinical measurement. \n",
    "- (C) Grouping articles on different topics from different news sources (something like the Google News app). \n",
    "- (D) Detecting credit card fraud based on examples of fraudulent and non-fraudulent transactions.\n",
    "- (E) Given some measure of employee performance, identify the key factors which are likely to influence their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iClicker Exercise 2.3 Classification vs regression\n",
    "\n",
    "**iClicker cloud join link: https://join.iclicker.com/FSLV**\n",
    "\n",
    "**Select all of the following statements which are examples of regression problems**\n",
    "\n",
    "- (A) Predicting the price of a house based on features such as number of bedrooms and the year built.\n",
    "- (B) Predicting if a house will sell or not based on features like the price of the house, number of rooms, etc.\n",
    "- (C) Predicting percentage grade in CPSC 330 based on past grades.\n",
    "- (D) Predicting whether you should bicycle tomorrow or not based on the weather forecast.\n",
    "- (E) Predicting appropriate thermostat temperature based on the wind speed and the number of people in a room.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Baselines [[video](https://youtu.be/6eT5cLL-2Vc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Check out [the accompanying video](https://youtu.be/6eT5cLL-2Vc) on this material. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Supervised learning (Reminder)\n",
    "\n",
    "- Training data $\\rightarrow$ Machine learning algorithm $\\rightarrow$ ML model \n",
    "- Unseen test data + ML model $\\rightarrow$ predictions\n",
    "\n",
    "<br>\n",
    "\n",
    "<!-- ![](../img/sup-learning.png) -->\n",
    "<img src=\"../img/sup-learning.png\" width=\"800\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Let's build a very simple supervised machine learning model for quiz2 grade prediction problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.398551Z",
     "iopub.status.busy": "2024-01-11T23:11:33.397790Z",
     "iopub.status.idle": "2024-01-11T23:11:33.418394Z",
     "shell.execute_reply": "2024-01-11T23:11:33.416472Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.398483Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.586447900Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv(\"data/quiz2-grade-toy-classification.csv\")\n",
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.420604Z",
     "iopub.status.busy": "2024-01-11T23:11:33.420153Z",
     "iopub.status.idle": "2024-01-11T23:11:33.428949Z",
     "shell.execute_reply": "2024-01-11T23:11:33.427927Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.420580Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.590553Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_df['quiz2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like \"not A+\" occurs more frequently than \"A+\". What if we predict \"not A+\" all the time? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Baselines \n",
    "\n",
    "**Baseline**\n",
    ": A simple machine learning algorithm based on simple rules of thumb. \n",
    "\n",
    "- For example, most frequent baseline always predicts the most frequent label in the training set. \n",
    "- Baselines provide a way to sanity check your machine learning model.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `DummyClassifier` \n",
    "\n",
    "- `sklearn`'s baseline model for classification  \n",
    "- Let's train `DummyClassifier` on the grade prediction dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Steps to train a classifier using `sklearn` \n",
    "\n",
    "1. Read the data\n",
    "2. Create $X$ and $y$\n",
    "3. Create a classifier object\n",
    "4. `fit` the classifier\n",
    "5. `predict` on new examples\n",
    "6. `score` the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.430613Z",
     "iopub.status.busy": "2024-01-11T23:11:33.430261Z",
     "iopub.status.idle": "2024-01-11T23:11:33.442703Z",
     "shell.execute_reply": "2024-01-11T23:11:33.441655Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.430570Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.594662900Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Create $X$ and $y$\n",
    "\n",
    "- $X$ &rarr; Feature vectors\n",
    "- $y$ &rarr; Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.445259Z",
     "iopub.status.busy": "2024-01-11T23:11:33.444377Z",
     "iopub.status.idle": "2024-01-11T23:11:33.455321Z",
     "shell.execute_reply": "2024-01-11T23:11:33.452496Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.445083Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.597663200Z"
    }
   },
   "outputs": [],
   "source": [
    "X = classification_df.drop(columns=[\"quiz2\"])\n",
    "y = classification_df[\"quiz2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Create a classifier object\n",
    "\n",
    "- `import` the appropriate classifier \n",
    "- **Create** an object of the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.465265Z",
     "iopub.status.busy": "2024-01-11T23:11:33.464776Z",
     "iopub.status.idle": "2024-01-11T23:11:33.471372Z",
     "shell.execute_reply": "2024-01-11T23:11:33.469277Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.465240Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.601661900Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier # import the classifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\") # Create a classifier object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `fit` the classifier\n",
    "\n",
    "- The \"**learning**\" is carried out when we call `fit` on the classifier object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.474335Z",
     "iopub.status.busy": "2024-01-11T23:11:33.473525Z",
     "iopub.status.idle": "2024-01-11T23:11:33.483211Z",
     "shell.execute_reply": "2024-01-11T23:11:33.481803Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.474248Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.605798300Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_clf.fit(X, y); # fit the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `predict` the target of given examples\n",
    "\n",
    "- We can predict the target of examples by calling `predict` on the classifier object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.487237Z",
     "iopub.status.busy": "2024-01-11T23:11:33.485131Z",
     "iopub.status.idle": "2024-01-11T23:11:33.498099Z",
     "shell.execute_reply": "2024-01-11T23:11:33.496496Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.487184Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.609797700Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_clf.predict(X) # predict using the trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.502906Z",
     "iopub.status.busy": "2024-01-11T23:11:33.501126Z",
     "iopub.status.idle": "2024-01-11T23:11:33.512682Z",
     "shell.execute_reply": "2024-01-11T23:11:33.511602Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.502844Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.613798800Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.514671Z",
     "iopub.status.busy": "2024-01-11T23:11:33.514173Z",
     "iopub.status.idle": "2024-01-11T23:11:33.526544Z",
     "shell.execute_reply": "2024-01-11T23:11:33.523772Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.514629Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.617912400Z"
    }
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.530938Z",
     "iopub.status.busy": "2024-01-11T23:11:33.528900Z",
     "iopub.status.idle": "2024-01-11T23:11:33.541796Z",
     "shell.execute_reply": "2024-01-11T23:11:33.540062Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.530861Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.620913200Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_clf.predict(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `score` your model\n",
    "\n",
    "- How do you know how well your model is doing?\n",
    "- For classification problems, by default, `score` gives the **accuracy** of the model, i.e., proportion of correctly predicted targets.  \n",
    "\n",
    "    $accuracy = \\frac{\\text{correct predictions}}{\\text{total examples}}$   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.544884Z",
     "iopub.status.busy": "2024-01-11T23:11:33.544412Z",
     "iopub.status.idle": "2024-01-11T23:11:33.555386Z",
     "shell.execute_reply": "2024-01-11T23:11:33.554001Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.544845Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.623915Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The accuracy of the model on the training data: %0.3f\" % \n",
    "    (dummy_clf.score(X, y))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Sometimes you will also see people reporting **error**, which is usually $1 - accuracy$ \n",
    "- `score` \n",
    "    - calls `predict` on `X` \n",
    "    - compares predictions with `y` (true targets)\n",
    "    - returns the accuracy in case of classification.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.558266Z",
     "iopub.status.busy": "2024-01-11T23:11:33.557366Z",
     "iopub.status.idle": "2024-01-11T23:11:33.566922Z",
     "shell.execute_reply": "2024-01-11T23:11:33.565722Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.558214Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.628911700Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The error of the model on the training data: %0.3f\" % \n",
    "    (1 - dummy_clf.score(X, y))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `fit`, `predict` , and `score` summary\n",
    "\n",
    "Here is the general pattern when we build ML models using `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.568683Z",
     "iopub.status.busy": "2024-01-11T23:11:33.568230Z",
     "iopub.status.idle": "2024-01-11T23:11:33.582695Z",
     "shell.execute_reply": "2024-01-11T23:11:33.581414Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.568634Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.632047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create `X` and `y` from the given data\n",
    "X = classification_df.drop(columns=[\"quiz2\"])\n",
    "y = classification_df[\"quiz2\"]\n",
    "\n",
    "clf = DummyClassifier(strategy=\"most_frequent\") # Create a class object\n",
    "clf.fit(X, y) # Train or \"fit\" the model\n",
    "print(clf.score(X, y)) # Assess the model\n",
    "\n",
    "new_examples = [\n",
    "    [0, 1, 92, 90, 95, 93, 92], \n",
    "    [1, 1, 92, 93, 94, 92]\n",
    "] # two new examples\n",
    "\n",
    "clf.predict(new_examples) # Predict on some new data using the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " \n",
    "You'll be exploring dummy classifier in your lab!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [`DummyRegressor`](https://scikit-learn.org/0.15/modules/generated/sklearn.dummy.DummyRegressor.html)\n",
    "\n",
    "You can also do the same thing for regression problems using `DummyRegressor`, which predicts mean, median, or constant value of the training set for all examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Let's build a regression baseline model using `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.584535Z",
     "iopub.status.busy": "2024-01-11T23:11:33.584037Z",
     "iopub.status.idle": "2024-01-11T23:11:33.603618Z",
     "shell.execute_reply": "2024-01-11T23:11:33.602604Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.584508Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.635044200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "regression_df = pd.read_csv(\"data/quiz2-grade-toy-regression.csv\") # Read data \n",
    "X = regression_df.drop(columns=[\"quiz2\"]) # Create `X` and `y` from the given data\n",
    "y = regression_df[\"quiz2\"]\n",
    "reg = DummyRegressor() # Create a class object\n",
    "reg.fit(X, y) # Train/fit the model\n",
    "reg.score(X, y) # Assess the model\n",
    "new_examples = [[0, 1, 92, 90, 95, 93, 92], [1, 1, 92, 93, 94, 92]]\n",
    "reg.predict(new_examples) # Predict on some new data using the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The `fit` and `predict` paradigms similar to classification. The `score` method in the context of regression returns somethings called [$R^2$ score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score). (More on this in later videos.)     \n",
    "    - The maximum $R^2$ is 1 for perfect predictions. \n",
    "    - For `DummyRegressor` it returns the mean of the `y` values.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.606169Z",
     "iopub.status.busy": "2024-01-11T23:11:33.605041Z",
     "iopub.status.idle": "2024-01-11T23:11:33.617312Z",
     "shell.execute_reply": "2024-01-11T23:11:33.615308Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.606114Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.638043500Z"
    }
   },
   "outputs": [],
   "source": [
    "reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.619841Z",
     "iopub.status.busy": "2024-01-11T23:11:33.619343Z",
     "iopub.status.idle": "2024-01-11T23:11:33.629145Z",
     "shell.execute_reply": "2024-01-11T23:11:33.628129Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.619796Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.641047100Z"
    }
   },
   "outputs": [],
   "source": [
    "# DummyRegressor returns the mean of the y values:\n",
    "[y.mean(), reg.predict(new_examples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ❓❓ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Exercise 2.4\n",
    "1. Order the steps below to build ML models using `sklearn`. \n",
    "    - `score` to evaluate the performance of a given model\n",
    "    - `predict` on new examples \n",
    "    - Creating a model instance\n",
    "    - Creating `X` and `y` \n",
    "    - `fit`\n",
    "2. `predict` takes only `X` as argument whereas `fit` and `score` take both `X` and `y` as arguments. True or False. \n",
    "3. Have you ever played [20-questions game](https://en.wikipedia.org/wiki/Twenty_questions)? If yes, think about how do you decide what question to ask next? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Exercise 2.4: Solution\n",
    "\n",
    "1. Ordered steps\n",
    "    - Creating `X` and `y` \n",
    "    - Creating a model instance\n",
    "    - `fit`\n",
    "    - `predict` on new examples \n",
    "    - `score` to evaluate the performance of a given model\n",
    "2. True\n",
    "3. Open-ended. (We'll see how decision trees work next.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break (5 min)\n",
    "\n",
    "![](../img/eva-coffee.png)\n",
    "\n",
    "- We will try to take a 5-minute break half way through every class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision trees [[video](https://youtu.be/Hcf19Ij35rA)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Check out [the accompanying video](https://youtu.be/Hcf19Ij35rA) on this material. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Writing a traditional program to predict quiz2 grade\n",
    "\n",
    "- Can we do better than the baseline? \n",
    "- Forget about ML for a second. If you are asked to write a program to predict whether a student gets an A+ or not in quiz2, how would you go for it?  \n",
    "- For simplicity, let's binarize the feature values. \n",
    "\n",
    "<!-- ![](../img/quiz2-grade-toy.png) -->\n",
    "\n",
    "<img src=\"../img/quiz2-grade-toy.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Is there a pattern that distinguishes yes's from no's and what does the pattern say about today? \n",
    "- How about a rule-based algorithm with a number of *if else* statements?  \n",
    "    ```\n",
    "    if class_attendance == 1 and quiz1 == 1:\n",
    "        quiz2 == \"A+\"\n",
    "    elif class_attendance == 1 and lab3 == 1 and lab4 == 1:\n",
    "        quiz2 == \"A+\"\n",
    "    ...\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- How many possible rule combinations there could be with the given 7 binary features? \n",
    "    - Gets unwieldy pretty quickly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision tree algorithm \n",
    "\n",
    "- A machine learning algorithm to derive such rules from data in a principled way.  \n",
    "- Have you ever played [20-questions game](https://en.wikipedia.org/wiki/Twenty_questions)? Decision trees are based on the same idea! \n",
    "- Let's `fit` a decision tree using `scikit-learn` and `predict` with it.\n",
    "- Recall that `scikit-learn` uses the term `fit` for training or learning and uses `predict` for prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building decision trees with `sklearn`\n",
    "\n",
    "Let's **binarize** our toy dataset for simplicity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.630476Z",
     "iopub.status.busy": "2024-01-11T23:11:33.630131Z",
     "iopub.status.idle": "2024-01-11T23:11:33.650478Z",
     "shell.execute_reply": "2024-01-11T23:11:33.648472Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.630433Z"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.643044900Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv(\"data/quiz2-grade-toy-classification.csv\")\n",
    "X = classification_df.drop(columns=[\"quiz2\"])\n",
    "y = classification_df[\"quiz2\"]\n",
    "\n",
    "X_binary = X.copy()\n",
    "columns = [\"lab1\", \"lab2\", \"lab3\", \"lab4\", \"quiz1\"]\n",
    "for col in columns:\n",
    "    X_binary[col] = X_binary[col].apply(lambda x: 1 if x >= 90 else 0)\n",
    "\n",
    "X_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.653568Z",
     "iopub.status.busy": "2024-01-11T23:11:33.652509Z",
     "iopub.status.idle": "2024-01-11T23:11:33.662944Z",
     "shell.execute_reply": "2024-01-11T23:11:33.661613Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.653508Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.645652500Z"
    }
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.665153Z",
     "iopub.status.busy": "2024-01-11T23:11:33.664492Z",
     "iopub.status.idle": "2024-01-11T23:11:33.682074Z",
     "shell.execute_reply": "2024-01-11T23:11:33.678290Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.665124Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.647700300Z"
    }
   },
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.684894Z",
     "iopub.status.busy": "2024-01-11T23:11:33.684033Z",
     "iopub.status.idle": "2024-01-11T23:11:33.755209Z",
     "shell.execute_reply": "2024-01-11T23:11:33.753425Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.684848Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.649701400Z"
    }
   },
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `DummyClassifier` on quiz2 grade prediction toy dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.757544Z",
     "iopub.status.busy": "2024-01-11T23:11:33.756997Z",
     "iopub.status.idle": "2024-01-11T23:11:33.769338Z",
     "shell.execute_reply": "2024-01-11T23:11:33.767561Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.757491Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.651701100Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_binary, y)\n",
    "dummy_clf.score(X_binary, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### `DecisionTreeClassifier` on quiz2 grade prediction toy dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.773008Z",
     "iopub.status.busy": "2024-01-11T23:11:33.771344Z",
     "iopub.status.idle": "2024-01-11T23:11:33.808652Z",
     "shell.execute_reply": "2024-01-11T23:11:33.806773Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.772950Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.652702500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier() # Create a decision tree\n",
    "model.fit(X_binary, y) # Fit a decision tree\n",
    "model.score(X_binary, y) # Assess the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree classifier is giving much higher accuracy than the dummy classifier. That's good news! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:33.810702Z",
     "iopub.status.busy": "2024-01-11T23:11:33.810247Z",
     "iopub.status.idle": "2024-01-11T23:11:34.561745Z",
     "shell.execute_reply": "2024-01-11T23:11:34.560667Z",
     "shell.execute_reply.started": "2024-01-11T23:11:33.810674Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.654693900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call the custom_plot_tree function to visualize the customized tree\n",
    "width=12 \n",
    "height = 8\n",
    "plt.figure(figsize=(width, height))\n",
    "custom_plot_tree(model, \n",
    "                 feature_names=X_binary.columns.tolist(), \n",
    "                 class_names=['A+', 'not A+'],\n",
    "                 impurity=False,\n",
    "                 fontsize=10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some terminology related to trees \n",
    "\n",
    "Here is a commonly used terminology in a typical representation of decision trees. \n",
    "\n",
    "**A root node**\n",
    ": represents the *first condition* to check or question to ask\n",
    "\n",
    "**A branch**\n",
    ": *connects* a node (condition) to the next node (condition) in the tree. Each branch typically represents either true or false. \n",
    "\n",
    "**An internal node** \n",
    ": represents conditions *within* the tree\n",
    "\n",
    "**A leaf node**\n",
    ": represents the *predicted class/value* when the path from root to the leaf node is followed. \n",
    "\n",
    "**Tree depth**\n",
    ": The *number of edges* on the path from the root node to the farthest away leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How does `predict` work? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:34.563497Z",
     "iopub.status.busy": "2024-01-11T23:11:34.563184Z",
     "iopub.status.idle": "2024-01-11T23:11:34.574939Z",
     "shell.execute_reply": "2024-01-11T23:11:34.573491Z",
     "shell.execute_reply.started": "2024-01-11T23:11:34.563476Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.657698400Z"
    }
   },
   "outputs": [],
   "source": [
    "new_example = np.array([[0, 1, 0, 0, 1, 1, 1]])\n",
    "new_example = pd.DataFrame(data=new_example, columns=X.columns)\n",
    "new_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:34.577363Z",
     "iopub.status.busy": "2024-01-11T23:11:34.576482Z",
     "iopub.status.idle": "2024-01-11T23:11:35.252443Z",
     "shell.execute_reply": "2024-01-11T23:11:35.251213Z",
     "shell.execute_reply.started": "2024-01-11T23:11:34.577304Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.660698800Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "custom_plot_tree(model, \n",
    "                 feature_names=X_binary.columns.tolist(), \n",
    "                 class_names=['A+', 'not A+'],\n",
    "                 impurity=False,\n",
    "                 fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What's the prediction for the new example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:35.253679Z",
     "iopub.status.busy": "2024-01-11T23:11:35.253388Z",
     "iopub.status.idle": "2024-01-11T23:11:35.262918Z",
     "shell.execute_reply": "2024-01-11T23:11:35.261611Z",
     "shell.execute_reply.started": "2024-01-11T23:11:35.253654Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.663695100Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(new_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In summary, given a learned tree and a test example, during prediction time,  \n",
    "- Start at the top of the tree. Ask binary questions at each node and follow the appropriate path in the tree. Once you are at a leaf node, you have the prediction. \n",
    "- Note that the model only considers the features which are in the learned tree and ignores all other features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How does `fit` work? \n",
    "\n",
    "- Decision tree is inspired by [20-questions game](https://en.wikipedia.org/wiki/Twenty_questions). \n",
    "- Each node either represents a question or an answer. The terminal nodes (called leaf nodes) represent answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:35.264621Z",
     "iopub.status.busy": "2024-01-11T23:11:35.264264Z",
     "iopub.status.idle": "2024-01-11T23:11:35.439603Z",
     "shell.execute_reply": "2024-01-11T23:11:35.438329Z",
     "shell.execute_reply.started": "2024-01-11T23:11:35.264596Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.665694500Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_fruit_tree() # defined in code/plotting_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### How does `fit` work? \n",
    "\n",
    "- Which features are most useful for classification? \n",
    "- Minimize **impurity** at each question\n",
    "- Common criteria to minimize impurity: [gini index](https://scikit-learn.org/stable/modules/tree.html#classification-criteria), information gain, cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:35.442226Z",
     "iopub.status.busy": "2024-01-11T23:11:35.441499Z",
     "iopub.status.idle": "2024-01-11T23:11:36.214990Z",
     "shell.execute_reply": "2024-01-11T23:11:36.213868Z",
     "shell.execute_reply.started": "2024-01-11T23:11:35.442194Z"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.668692400Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier() # Create a decision tree\n",
    "model.fit(X_binary, y) # Fit a decision tree\n",
    "plt.figure(figsize=(width, height))\n",
    "custom_plot_tree(model, \n",
    "                 feature_names=X_binary.columns.tolist(), \n",
    "                 class_names=['A+', 'not A+'],\n",
    "                 fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "___\n",
    "\n",
    "We won't go through **how** it does this - that's CPSC 340. \n",
    "\n",
    "But it's worth noting that it support two types of inputs:\n",
    "\n",
    "1. Categorical (e.g., Yes/No or more options, as shown in the tree above)\n",
    "2. Numeric (a number), the decision tree algorithm also picks the *threshold*\n",
    "    \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision trees with **continuous** features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:36.216673Z",
     "iopub.status.busy": "2024-01-11T23:11:36.216344Z",
     "iopub.status.idle": "2024-01-11T23:11:36.228812Z",
     "shell.execute_reply": "2024-01-11T23:11:36.227523Z",
     "shell.execute_reply.started": "2024-01-11T23:11:36.216652Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.671692500Z"
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:36.230643Z",
     "iopub.status.busy": "2024-01-11T23:11:36.230287Z",
     "iopub.status.idle": "2024-01-11T23:11:36.798522Z",
     "shell.execute_reply": "2024-01-11T23:11:36.796493Z",
     "shell.execute_reply.started": "2024-01-11T23:11:36.230599Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.673839700Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "plt.figure(figsize=(width, height))\n",
    "custom_plot_tree(model, \n",
    "                 feature_names=X_binary.columns.tolist(), \n",
    "                 class_names=['A+', 'not A+'],\n",
    "                 impurity=False,\n",
    "                 fontsize=10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision tree for regression problems\n",
    "\n",
    "- We can also use decision tree algorithm for regression. \n",
    "- Instead of gini, we use [some other criteria](https://scikit-learn.org/stable/modules/tree.html#mathematical-formulation) for splitting. A common one is mean squared error (MSE). (More on this in later videos.)\n",
    "- `scikit-learn` supports regression using decision trees with `DecisionTreeRegressor` \n",
    "    - `fit` and `predict` paradigms similar to classification\n",
    "    - `score` returns somethings called [$R^2$ score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score).     \n",
    "        - The maximum $R^2$ is 1 for perfect predictions. \n",
    "        - It can be negative which is very bad (worse than `DummyRegressor`). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:36.800324Z",
     "iopub.status.busy": "2024-01-11T23:11:36.799998Z",
     "iopub.status.idle": "2024-01-11T23:11:36.818963Z",
     "shell.execute_reply": "2024-01-11T23:11:36.817754Z",
     "shell.execute_reply.started": "2024-01-11T23:11:36.800302Z"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.676843300Z"
    }
   },
   "outputs": [],
   "source": [
    "regression_df = pd.read_csv(\"data/quiz2-grade-toy-regression.csv\")\n",
    "regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:36.820252Z",
     "iopub.status.busy": "2024-01-11T23:11:36.819966Z",
     "iopub.status.idle": "2024-01-11T23:11:36.849534Z",
     "shell.execute_reply": "2024-01-11T23:11:36.848141Z",
     "shell.execute_reply.started": "2024-01-11T23:11:36.820216Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.679836800Z"
    }
   },
   "outputs": [],
   "source": [
    "X = regression_df.drop([\"quiz2\"], axis=1)\n",
    "y = regression_df[\"quiz2\"]\n",
    "\n",
    "depth = 2\n",
    "reg_model = DecisionTreeRegressor(max_depth=depth)\n",
    "reg_model.fit(X, y); \n",
    "regression_df[\"predicted_quiz2\"] = reg_model.predict(X)\n",
    "print(\"R^2 score on the training data: %0.3f\\n\\n\" % (reg_model.score(X, y)))\n",
    "regression_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ❓❓ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iClicker Exercise 2.5 Baselines and decision trees\n",
    "\n",
    "**iClicker cloud join link: https://join.iclicker.com/FSLV**\n",
    "\n",
    "**Select all of the following statements which are TRUE.**\n",
    "\n",
    "- (A) Change in features (i.e., binarizing features above) would change `DummyClassifier` predictions. \n",
    "- (B) `predict` takes only `X` as argument whereas `fit` and `score` take both `X` and `y` as arguments. \n",
    "- (C) For the decision tree algorithm to work, the feature values must be binary.\n",
    "- (D) The prediction in a decision tree works by routing the example from the root to the leaf.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 2.6\n",
    "1. Should change in features (i.e., binarizing features above) change `DummyClassifier` predictions? \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.6: Solution\n",
    "\n",
    "1. No. `DummyClassifier` does not look at the features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 2.7 True or False \n",
    "1. For the decision tree algorithm to work, the feature values must be numeric.  \n",
    "2. For the decision tree algorithm to work, the target values must be numeric.\n",
    "3. The decision tree algorithm creates balanced decision trees. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.7: Solution\n",
    "\n",
    "1. False\n",
    "2. False\n",
    "3. False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More terminology [[video](https://youtu.be/KEtsfXn4w2E)]\n",
    "\n",
    "- Parameters and hyperparameters\n",
    "- Decision boundary \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Check out [the accompanying video](https://youtu.be/KEtsfXn4w2E) on this material. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameters \n",
    "\n",
    "- The decision tree algorithm primarily **learns two** things: \n",
    "    - the **best feature** to split on\n",
    "    - the **threshold** for the feature to split on at each node\n",
    "- These are called ***parameters*** of the decision tree model.  \n",
    "- When predicting on new examples, we need parameters of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:36.852062Z",
     "iopub.status.busy": "2024-01-11T23:11:36.851160Z",
     "iopub.status.idle": "2024-01-11T23:11:36.869816Z",
     "shell.execute_reply": "2024-01-11T23:11:36.867388Z",
     "shell.execute_reply.started": "2024-01-11T23:11:36.851885Z"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.682844500Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv(\"data/quiz2-grade-toy-classification.csv\")\n",
    "X = classification_df.drop(columns=[\"quiz2\"])\n",
    "y = classification_df[\"quiz2\"]\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:36.873728Z",
     "iopub.status.busy": "2024-01-11T23:11:36.872561Z",
     "iopub.status.idle": "2024-01-11T23:11:36.893589Z",
     "shell.execute_reply": "2024-01-11T23:11:36.892614Z",
     "shell.execute_reply.started": "2024-01-11T23:11:36.873672Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.683999200Z"
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:36.895146Z",
     "iopub.status.busy": "2024-01-11T23:11:36.894777Z",
     "iopub.status.idle": "2024-01-11T23:11:37.489178Z",
     "shell.execute_reply": "2024-01-11T23:11:37.488306Z",
     "shell.execute_reply.started": "2024-01-11T23:11:36.895122Z"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.686997500Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "custom_plot_tree(model, \n",
    "                 feature_names=X_binary.columns.tolist(), \n",
    "                 class_names=['A+', 'not A+'],\n",
    "                 impurity=False,\n",
    "                 fontsize=10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- With the default setting, the nodes are expanded until all leaves are \"**pure**\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The decision tree is creating very specific rules, based on just one example from the data. \n",
    "- Is it possible to control the learning in any way? \n",
    "    - Yes! One way to do it is by controlling the **depth** of the tree, which is the length of the longest path from the tree root to a leaf.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision tree with `max_depth=1`\n",
    "\n",
    "**Decision stump**\n",
    ": A decision tree with only one split (depth=1) is called a **decision stump**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:37.491100Z",
     "iopub.status.busy": "2024-01-11T23:11:37.490485Z",
     "iopub.status.idle": "2024-01-11T23:11:37.660771Z",
     "shell.execute_reply": "2024-01-11T23:11:37.659600Z",
     "shell.execute_reply.started": "2024-01-11T23:11:37.491076Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.689099100Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=1)\n",
    "model.fit(X, y)\n",
    "width=8;height=2\n",
    "plt.figure(figsize=(width, height))\n",
    "custom_plot_tree(model, \n",
    "                 feature_names=X_binary.columns.tolist(), \n",
    "                 class_names=['A+', 'not A+'],\n",
    "                 impurity=False,                \n",
    "                 fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`max_depth` is a **hyperparameter** of `DecisionTreeClassifier`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision tree with `max_depth=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:37.665134Z",
     "iopub.status.busy": "2024-01-11T23:11:37.663458Z",
     "iopub.status.idle": "2024-01-11T23:11:38.048291Z",
     "shell.execute_reply": "2024-01-11T23:11:38.047055Z",
     "shell.execute_reply.started": "2024-01-11T23:11:37.665061Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.690102500Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    max_depth=3\n",
    ")  # Let's try another value for the hyperparameter\n",
    "model.fit(X, y)\n",
    "width=10;height=5\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "custom_plot_tree(model, \n",
    "                 feature_names=X_binary.columns.tolist(), \n",
    "                 class_names=['A+', 'not A+'],\n",
    "                 impurity=False,                \n",
    "                 fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameters and hyperparameters: Summary \n",
    "**Parameters**\n",
    ": When you call `fit`, a bunch of values get set, like the features to split on and split thresholds. These are called **parameters**. These are learned by the algorithm from the data during training. We need them during prediction time. \n",
    "\n",
    "**Hyperparameters**\n",
    ": Even before calling `fit` on a specific data set, we can set some \"knobs\" that control the learning. These are called **hyperparameters**. These are specified based on: expert knowledge, heuristics, or systematic/automated optimization (more on this in the coming lectures).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "___\n",
    "In `sklearn` hyperparameters are set in the constructor. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Above we looked at the `max_depth` hyperparameter. Some other commonly used hyperparameters of decision tree are:\n",
    "\n",
    "- `min_samples_split`\n",
    "- `min_samples_leaf`\n",
    "- `max_leaf_nodes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "___\n",
    "See [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for other hyperparameters of a tree.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision boundary \n",
    "\n",
    "What do we do with learned models? So far we have been using them to predict the class of a new instance. Another way to think about them is to ask: what sort of test examples will the model classify as positive, and what sort will it classify as negative? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example 1: quiz 2 grade prediction \n",
    "\n",
    "For visualization purposes, let's consider a subset of the data with only two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:38.050721Z",
     "iopub.status.busy": "2024-01-11T23:11:38.049952Z",
     "iopub.status.idle": "2024-01-11T23:11:38.062218Z",
     "shell.execute_reply": "2024-01-11T23:11:38.060400Z",
     "shell.execute_reply.started": "2024-01-11T23:11:38.050683Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.692104200Z"
    }
   },
   "outputs": [],
   "source": [
    "X_subset = X[[\"lab4\", \"quiz1\"]]\n",
    "X_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Decision boundary for `max_depth=1`\n",
    "\n",
    "A decision tree with only one split (depth=1) is called a **decision stump**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:38.065580Z",
     "iopub.status.busy": "2024-01-11T23:11:38.064115Z",
     "iopub.status.idle": "2024-01-11T23:11:38.467413Z",
     "shell.execute_reply": "2024-01-11T23:11:38.466131Z",
     "shell.execute_reply.started": "2024-01-11T23:11:38.065538Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.694100900Z"
    }
   },
   "outputs": [],
   "source": [
    "depth = 1  # decision stump\n",
    "model = DecisionTreeClassifier(max_depth=depth)\n",
    "model.fit(X_subset.values, y)\n",
    "plot_tree_decision_boundary_and_tree(\n",
    "    model, X_subset, y, x_label=\"lab4\", y_label=\"quiz1\", fontsize=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We assume geometric view of the data. Here, the red region corresponds to \"not A+\" class and blue region corresponds to \"A+\" class. And there is a line separating the red region and the blue region which is called the **decision boundary** of the model. Different models have different kinds of decision boundaries. \n",
    "In decision tree models, when we are working with only two features, the decision boundary is made up of horizontal and vertical lines. In the example above, the decision boundary is created by asking one question `lab4 <= 84.5`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Decision boundary for `max_depth=2` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:38.470241Z",
     "iopub.status.busy": "2024-01-11T23:11:38.469272Z",
     "iopub.status.idle": "2024-01-11T23:11:38.901372Z",
     "shell.execute_reply": "2024-01-11T23:11:38.900051Z",
     "shell.execute_reply.started": "2024-01-11T23:11:38.470170Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.696100300Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(X_subset.values, y)\n",
    "plot_tree_decision_boundary_and_tree(\n",
    "    model, X_subset, y, x_label=\"lab4\", y_label=\"quiz1\", fontsize=12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundary, i.e., the model gets a bit more complicated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Decision boundary for `max_depth=5` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:38.904215Z",
     "iopub.status.busy": "2024-01-11T23:11:38.903156Z",
     "iopub.status.idle": "2024-01-11T23:11:39.654849Z",
     "shell.execute_reply": "2024-01-11T23:11:39.653825Z",
     "shell.execute_reply.started": "2024-01-11T23:11:38.904174Z"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.698099Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "model.fit(X_subset.values, y)\n",
    "plot_tree_decision_boundary_and_tree(\n",
    "    model, X_subset, y, x_label=\"lab4\", y_label=\"quiz1\", fontsize=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundary, i.e., the model gets even more complicated with `max_depth=5`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example 2: Predicting country using the longitude and latitude \n",
    "\n",
    "Imagine that you are given longitude and latitude of some border cities of USA and Canada along with which country they belong to. Using this training data, you are supposed to come up with a classification model to predict whether a given longitude and latitude combination is in the USA or Canada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:39.656896Z",
     "iopub.status.busy": "2024-01-11T23:11:39.656048Z",
     "iopub.status.idle": "2024-01-11T23:11:39.674435Z",
     "shell.execute_reply": "2024-01-11T23:11:39.672644Z",
     "shell.execute_reply.started": "2024-01-11T23:11:39.656805Z"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.701102600Z"
    }
   },
   "outputs": [],
   "source": [
    "### US Canada cities data\n",
    "df = pd.read_csv(\"data/canada_usa_cities.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:39.677381Z",
     "iopub.status.busy": "2024-01-11T23:11:39.676252Z",
     "iopub.status.idle": "2024-01-11T23:11:39.686906Z",
     "shell.execute_reply": "2024-01-11T23:11:39.684943Z",
     "shell.execute_reply.started": "2024-01-11T23:11:39.677330Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.703098500Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df[[\"longitude\", \"latitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:39.690026Z",
     "iopub.status.busy": "2024-01-11T23:11:39.689278Z",
     "iopub.status.idle": "2024-01-11T23:11:39.699110Z",
     "shell.execute_reply": "2024-01-11T23:11:39.697359Z",
     "shell.execute_reply.started": "2024-01-11T23:11:39.689973Z"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.706211600Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df[\"country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:39.700727Z",
     "iopub.status.busy": "2024-01-11T23:11:39.700399Z",
     "iopub.status.idle": "2024-01-11T23:11:40.003845Z",
     "shell.execute_reply": "2024-01-11T23:11:40.000907Z",
     "shell.execute_reply.started": "2024-01-11T23:11:39.700689Z"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.709211100Z"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.discrete_scatter(X.iloc[:, 0], X.iloc[:, 1], y)\n",
    "plt.xlabel(\"longitude\")\n",
    "plt.ylabel(\"latitude\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Real boundary between Canada and USA\n",
    "\n",
    "In real life we know what's the boundary between USA and Canada. \n",
    "\n",
    "<!-- ![](../img/canada-us-border.jpg) -->\n",
    "\n",
    "<img src=\"../img/canada-us-border.jpg\" width=\"800\"> \n",
    "\n",
    "[Source](https://sovereignlimits.com/blog/u-s-canada-border-history-disputes)\n",
    "\n",
    "Here we want to pretend that we do not know this boundary and we want to infer this boundary based on the limited training examples given to us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:40.006010Z",
     "iopub.status.busy": "2024-01-11T23:11:40.005461Z",
     "iopub.status.idle": "2024-01-11T23:11:40.383280Z",
     "shell.execute_reply": "2024-01-11T23:11:40.382335Z",
     "shell.execute_reply.started": "2024-01-11T23:11:40.005959Z"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.711218400Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=1)\n",
    "model.fit(X.values, y)\n",
    "plot_tree_decision_boundary_and_tree(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    height=6,\n",
    "    width=16,\n",
    "    fontsize=15,\n",
    "    eps=10,\n",
    "    x_label=\"longitude\",\n",
    "    y_label=\"latitude\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T23:11:40.385126Z",
     "iopub.status.busy": "2024-01-11T23:11:40.384541Z",
     "iopub.status.idle": "2024-01-11T23:11:40.971520Z",
     "shell.execute_reply": "2024-01-11T23:11:40.969968Z",
     "shell.execute_reply.started": "2024-01-11T23:11:40.385102Z"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "ExecuteTime": {
     "start_time": "2024-01-12T00:34:19.714211500Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(X.values, y)\n",
    "plot_tree_decision_boundary_and_tree(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    height=6,\n",
    "    width=16,\n",
    "    fontsize=12,\n",
    "    eps=10,\n",
    "    x_label=\"longitude\",\n",
    "    y_label=\"latitude\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice exercises \n",
    "\n",
    "- If you want more practice, check out module 2 in [this online course](https://ml-learn.mds.ubc.ca/en/module2). All the sections **without** video or notes symbol are exercises.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "If all of you are working on the exercises, especially coding exercises, at the same time, you might have to wait for the real-time feedback for a long time or you might even get an error. There is no solution for this other than waiting for a while and trying it again. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some background on [the online course](https://ml-learn.mds.ubc.ca/en/) above: This course is designed by Hayley Boyce, Mike Gelbart, and myself. It'll be a great resource at the beginning of this class, as it give you a chance to practice what we learn and the framework will provide you real-time feedback. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Final comments, summary, and reflection\n",
    "\n",
    "What did we learn today? \n",
    "\n",
    "- There is a lot of terminology and jargon used in ML. Some of the basic \n",
    "terminology includes:\n",
    "    - Features, target, examples, training\n",
    "    - Supervised vs. Unsupervised machine learning     \n",
    "    - Classification and regression    \n",
    "    - Accuracy and error    \n",
    "    - Parameters and hyperparameters\n",
    "    - Decision boundary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Baselines and steps to train a supervised machine learning model \n",
    "    - Baselines serve as reference points in ML workflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision trees    \n",
    "    - are models that make predictions by sequentially looking at features and checking whether they are above/below a threshold\n",
    "    - learn a hierarchy of if/else questions, similar to questions you might ask in a 20-questions game.       \n",
    "    - learn axis-aligned decision boundaries (vertical and horizontal lines with 2 features)    \n",
    "    - One way to control the complexity of decision tree models is by using the depth hyperparameter (`max_depth` in `sklearn`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/eva-logging-off.png)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
